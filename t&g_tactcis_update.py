# -*- coding: utf-8 -*-
"""T&G Tactcis Update.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16DAbDrhQ-wqPIJ4AucYbGf4090KaGCj6
"""

!pip install ultralytics
!pip install -U supervision
!pip install -U norfair opencv-python-headless
!pip install --upgrade --force-reinstall numpy

!pip uninstall -y numpy
!pip install numpy==1.23.5

# ✅ Imports
import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from ultralytics import YOLO
from norfair import Detection, Tracker
from google.colab import drive

# ✅ Mount Google Drive
drive.mount('/content/drive')

# ✅ Load YOLOv8 model
model = YOLO("yolov8s.pt")

# ✅ Input/output folders
video_folder = "/content/drive/MyDrive/Matches_Folder"
output_folder = "/content/drive/MyDrive/TG_TACTICS/Tracking_CSVs"
os.makedirs(output_folder, exist_ok=True)

# ✅ Norfair tracker setup
tracker = Tracker(
    distance_function="euclidean",
    distance_threshold=30
)

# ✅ Convert YOLO detections to Norfair format
def yolo_to_norfair(detections):
    norfair_detections = []
    for det in detections:
        x1, y1, x2, y2, conf = det
        cx = (x1 + x2) / 2
        cy = (y1 + y2) / 2
        point = np.array([cx, cy])
        norfair_detections.append(Detection(points=point, scores=np.array([conf])))
    return norfair_detections

# ✅ Process each video
for match_file in os.listdir(video_folder):
    if not match_file.endswith(".mp4"):
        continue

    match_path = os.path.join(video_folder, match_file)
    match_name = os.path.splitext(match_file)[0]
    temp_csv = os.path.join(output_folder, f"{match_name}_temp.csv")
    final_csv = os.path.join(output_folder, f"{match_name}_tracking.csv")

    # ✅ Skip if final CSV already exists
    if os.path.exists(final_csv):
        print(f"✅ Skipping {match_name}, already processed.")
        continue

    cap = cv2.VideoCapture(match_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_idx = 0

    # ✅ Load temp progress if exists
    results_list = []
    if os.path.exists(temp_csv):
        temp_df = pd.read_csv(temp_csv)
        if not temp_df.empty:
            results_list = temp_df.values.tolist()
            frame_idx = int(temp_df["frame"].max()) + 1
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            print(f"🔄 Resuming {match_name} from frame {frame_idx}")
    else:
        print(f"📸 Starting {match_name}... Total Frames: {total_frames}")

    # ✅ Track with progress bar
    with tqdm(total=total_frames, initial=frame_idx, desc=f"Tracking {match_name}") as pbar:
        while frame_idx < total_frames:
            ret, frame = cap.read()
            if not ret:
                break

            results = model.predict(frame, classes=[0], verbose=False)
            detections = results[0].boxes.xyxy.cpu().numpy() if results[0].boxes else []
            confs = results[0].boxes.conf.cpu().numpy() if results[0].boxes else []

            if len(detections) > 0:
                dets = [list(detections[i]) + [confs[i]] for i in range(len(detections))]
                norfair_detections = yolo_to_norfair(dets)
                tracked_objects = tracker.update(detections=norfair_detections)

                for t_obj in tracked_objects:
                    track_id = t_obj.id
                    cx, cy = t_obj.estimate[0]
                    for det in dets:
                        x1, y1, x2, y2, conf = det
                        if abs(cx - ((x1 + x2) / 2)) < 20 and abs(cy - ((y1 + y2) / 2)) < 20:
                            results_list.append([frame_idx, track_id, x1, y1, x2, y2, conf, "person"])
                            break

            # ✅ Save progress every 100 frames
            if frame_idx % 100 == 0:
                temp_df = pd.DataFrame(results_list, columns=["frame", "track_id", "x1", "y1", "x2", "y2", "confidence", "class"])
                temp_df.to_csv(temp_csv, index=False)

            frame_idx += 1
            pbar.update(1)

    cap.release()

    # ✅ Save final CSV
    final_df = pd.DataFrame(results_list, columns=["frame", "track_id", "x1", "y1", "x2", "y2", "confidence", "class"])
    final_df.to_csv(final_csv, index=False)
    print(f"✅ Final CSV saved: {final_csv}")

    # ✅ Delete temp file
    if os.path.exists(temp_csv):
        os.remove(temp_csv)

import cv2
from matplotlib import pyplot as plt

# Path to one of your match videos
test_video = "/content/drive/MyDrive/Matches_Folder/Match_1.mp4"

# Frame number to test (change this)
frame_to_test = 700

# Load frame
cap = cv2.VideoCapture(test_video)
cap.set(cv2.CAP_PROP_POS_FRAMES, frame_to_test)
ret, frame = cap.read()
cap.release()

if not ret:
    print(f"❌ Could not read frame {frame_to_test}")
else:
    # Run YOLO on the frame
    results = model.predict(frame, classes=[0], verbose=False)

    # Draw detections
    for box in results[0].boxes.xyxy:
        x1, y1, x2, y2 = box[:4].cpu().numpy()
        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)

    # Show frame with bounding boxes
    plt.figure(figsize=(10, 6))
    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    plt.axis("off")
    plt.title(f"YOLOv8 Detections on Frame {frame_to_test}")
    plt.show()

import cv2
from matplotlib import pyplot as plt

# Test frame from any match
test_video = "/content/drive/MyDrive/Matches_Folder/Match_1.mp4"
cap = cv2.VideoCapture(test_video)
cap.set(cv2.CAP_PROP_POS_FRAMES, 500)  # Jump to frame 500 (change if needed)
ret, frame = cap.read()
cap.release()

# Run YOLO on the test frame
results = model.predict(frame, classes=[0], verbose=False)
for box in results[0].boxes.xyxy:
    x1, y1, x2, y2 = box[:4].cpu().numpy()
    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)

# Show the frame
plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
plt.axis("off")
plt.title("✅ YOLO Detection Preview")
plt.show()

!pip uninstall -y numpy pandas
!pip install numpy==1.24.4 pandas==1.5.3

# ⚙️ Install dependencies (run this first if not already done)
!pip install ultralytics
!pip install -U supervision norfair opencv-python-headless

# ✅ Imports
import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from ultralytics import YOLO
from norfair import Detection, Tracker
from google.colab import drive

# ✅ Mount Google Drive
drive.mount('/content/drive')

# ✅ Load YOLOv8n model (fastest)
model = YOLO("yolov8n.pt")

# ✅ Paths
video_folder = "/content/drive/MyDrive/Matches_Folder"
output_folder = "/content/drive/MyDrive/TG_TACTICS/Tracking_CSVs"
os.makedirs(output_folder, exist_ok=True)

# ✅ Norfair Tracker
tracker = Tracker(distance_function="euclidean", distance_threshold=30)

# ✅ YOLO → Norfair conversion
def yolo_to_norfair(detections):
    norfair_detections = []
    for det in detections:
        x1, y1, x2, y2, conf = det
        cx = (x1 + x2) / 2
        cy = (y1 + y2) / 2
        point = np.array([cx, cy])
        norfair_detections.append(Detection(points=point, scores=np.array([conf])))
    return norfair_detections

# ✅ Speed settings
frame_skip = 2

# ✅ Process each match
for match_file in os.listdir(video_folder):
    if not match_file.endswith(".mp4"):
        continue

    match_path = os.path.join(video_folder, match_file)
    match_name = os.path.splitext(match_file)[0]
    temp_csv = os.path.join(output_folder, f"{match_name}_temp.csv")
    final_csv = os.path.join(output_folder, f"{match_name}_tracking.csv")

    if os.path.exists(final_csv):
        print(f"✅ Skipping {match_name}, already processed.")
        continue

    cap = cv2.VideoCapture(match_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_idx = 0

    results_list = []
    if os.path.exists(temp_csv):
        temp_df = pd.read_csv(temp_csv)
        if not temp_df.empty:
            results_list = temp_df.values.tolist()
            frame_idx = int(temp_df["frame"].max()) + 1
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            print(f"🔄 Resuming {match_name} from frame {frame_idx}")
    else:
        print(f"📸 Starting {match_name}... Total Frames: {total_frames}")

    with tqdm(total=total_frames, initial=frame_idx, desc=f"Tracking {match_name}") as pbar:
        while frame_idx < total_frames:
            ret, frame = cap.read()
            if not ret:
                break

            if frame_idx % frame_skip != 0:
                frame_idx += 1
                pbar.update(1)
                continue

            # ✅ Resize frame for speed
            frame = cv2.resize(frame, (640, 360))

            # ✅ Run YOLO (no class filter to avoid IndexError)
            results = model.predict(frame, verbose=False)
            boxes = results[0].boxes

            # ✅ Filter only "person" class manually (class 0)
            if boxes and boxes.cls is not None:
                people = boxes.cls.cpu().numpy() == 0
                detections = boxes.xyxy.cpu().numpy()[people]
                confs = boxes.conf.cpu().numpy()[people]
            else:
                detections, confs = [], []

            # ✅ Track using Norfair
            if len(detections) > 0:
                dets = [list(detections[i]) + [confs[i]] for i in range(len(detections))]
                norfair_detections = yolo_to_norfair(dets)
                tracked_objects = tracker.update(detections=norfair_detections)

                for t_obj in tracked_objects:
                    track_id = t_obj.id
                    cx, cy = t_obj.estimate[0]
                    for det in dets:
                        x1, y1, x2, y2, conf = det
                        if abs(cx - ((x1 + x2) / 2)) < 20 and abs(cy - ((y1 + y2) / 2)) < 20:
                            results_list.append([frame_idx, track_id, x1, y1, x2, y2, conf, "person"])
                            break

            # ✅ Save progress every 100 frames
            if frame_idx % 100 == 0:
                temp_df = pd.DataFrame(results_list, columns=["frame", "track_id", "x1", "y1", "x2", "y2", "confidence", "class"])
                temp_df.to_csv(temp_csv, index=False)

            frame_idx += 1
            pbar.update(1)

    cap.release()

    # ✅ Save final CSV
    final_df = pd.DataFrame(results_list, columns=["frame", "track_id", "x1", "y1", "x2", "y2", "confidence", "class"])
    final_df.to_csv(final_csv, index=False)
    print(f"✅ Final CSV saved: {final_csv}")

    if os.path.exists(temp_csv):
        os.remove(temp_csv)

# 🛠 Install required libraries
!pip install ultralytics
!pip install -U supervision norfair opencv-python-headless

# ✅ Imports
import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from ultralytics import YOLO
from norfair import Detection, Tracker
from google.colab import drive
import torch

# ✅ Mount Google Drive
drive.mount('/content/drive')

# ✅ Confirm GPU (should be False for now, but check)
print("🔍 GPU available:", torch.cuda.is_available())

# ✅ Load YOLOv8 Nano model
model = YOLO("yolov8n.pt")

# ✅ Paths
video_folder = "/content/drive/MyDrive/Matches_Folder"
output_folder = "/content/drive/MyDrive/TG_TACTICS/Tracking_CSVs"
os.makedirs(output_folder, exist_ok=True)

# ✅ Norfair Tracker tuned for speed
tracker = Tracker(distance_function="euclidean", distance_threshold=15)

# ✅ Convert YOLO detections to Norfair format
def yolo_to_norfair(detections):
    norfair_detections = []
    for det in detections:
        x1, y1, x2, y2, conf = det
        cx = (x1 + x2) / 2
        cy = (y1 + y2) / 2
        point = np.array([cx, cy])
        norfair_detections.append(Detection(points=point, scores=np.array([conf])))
    return norfair_detections

# ✅ Speed Settings
frame_skip = 5
resize_to = (480, 270)
save_every = 25

# ✅ Resume Only Match_4
match_name = "Match_4"
match_path = os.path.join(video_folder, f"{match_name}.mp4")
temp_csv = os.path.join(output_folder, f"{match_name}_temp.csv")
final_csv = os.path.join(output_folder, f"{match_name}_tracking.csv")

# ✅ Skip if already done
if os.path.exists(final_csv):
    print(f"✅ {match_name} already completed.")
else:
    cap = cv2.VideoCapture(match_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_idx = 0
    results_list = []

    # ✅ Option 2: Load old temp file with 8 columns
    if os.path.exists(temp_csv):
        temp_df = pd.read_csv(temp_csv, header=None)  # Load without column names
        if not temp_df.empty:
            results_list = temp_df.values.tolist()
            frame_idx = int(temp_df.iloc[:, 0].max()) + 1
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            print(f"🔄 Resuming {match_name} from frame {frame_idx}")
    else:
        print(f"📸 Starting {match_name} from frame 0... Total Frames: {total_frames}")

    with tqdm(total=total_frames, initial=frame_idx, desc=f"Tracking {match_name}") as pbar:
        while frame_idx < total_frames:
            ret, frame = cap.read()
            if not ret:
                break

            if frame_idx % frame_skip != 0:
                frame_idx += 1
                pbar.update(1)
                continue

            # ✅ Resize frame
            frame = cv2.resize(frame, resize_to)

            # ✅ Run YOLO (FP16 if GPU available)
            results = model.predict(frame, verbose=False, half=True)
            boxes = results[0].boxes

            # ✅ Keep only "person" class
            if boxes and boxes.cls is not None:
                people = boxes.cls.cpu().numpy() == 0
                detections = boxes.xyxy.cpu().numpy()[people]
                confs = boxes.conf.cpu().numpy()[people]
            else:
                detections, confs = [], []

            # ✅ Run tracking
            if len(detections) > 0:
                dets = [list(detections[i]) + [confs[i]] for i in range(len(detections))]
                norfair_detections = yolo_to_norfair(dets)
                tracked_objects = tracker.update(detections=norfair_detections)

                for t_obj in tracked_objects:
                    track_id = t_obj.id
                    cx, cy = t_obj.estimate[0]
                    for det in dets:
                        x1, y1, x2, y2, conf = det
                        if abs(cx - ((x1 + x2) / 2)) < 20 and abs(cy - ((y1 + y2) / 2)) < 20:
                            results_list.append([frame_idx, track_id, x1, y1, x2, y2])
                            break

            # ✅ Save progress
            if frame_idx % save_every == 0:
                temp_df = pd.DataFrame(results_list)  # No column names
                temp_df.to_csv(temp_csv, index=False)

            frame_idx += 1
            pbar.update(1)

    cap.release()

    # ✅ Save final tracking CSV (clean)
    final_df = pd.DataFrame(results_list, columns=["frame", "track_id", "x1", "y1", "x2", "y2"])
    final_df.to_csv(final_csv, index=False)
    print(f"✅ Done: {final_csv}")

    if os.path.exists(temp_csv):
        os.remove(temp_csv)

import os
import cv2
import pandas as pd
from tqdm import tqdm
from google.colab import drive

# ✅ Mount Drive
drive.mount('/content/drive')

# 🔧 Paths
match_name = "Match_3"
video_path = f"/content/drive/MyDrive/Matches_Folder/{match_name}.mp4"
csv_path = f"/content/drive/MyDrive/TG_TACTICS/Tracking_CSVs/{match_name}_tracking.csv"
output_base = f"/content/drive/MyDrive/TG_TACTICS/Cropped_Faces/{match_name}"
os.makedirs(output_base, exist_ok=True)

# ✅ Load tracking data
df = pd.read_csv(csv_path)

# ✅ Open video
cap = cv2.VideoCapture(video_path)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# ✅ Cropping settings
crop_size = (160, 160)  # Faster resize
save_every = 100        # Just for console logs

pbar = tqdm(total=len(df), desc=f"⚡ Fast Cropping {match_name}")
processed = 0

for _, row in df.iterrows():
    frame_num = int(row["frame"])
    track_id = int(row["track_id"])
    x1, y1, x2, y2 = map(int, [row["x1"], row["y1"], row["x2"], row["y2"]])

    # ✅ Output path
    track_folder = os.path.join(output_base, f"track_{track_id}")
    os.makedirs(track_folder, exist_ok=True)
    crop_path = os.path.join(track_folder, f"frame_{frame_num:05}.jpg")

    if os.path.exists(crop_path):
        pbar.update(1)
        continue

    # ✅ Set video to correct frame and grab
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
    ret, frame = cap.read()
    if not ret or frame is None:
        pbar.update(1)
        continue

    # ✅ Crop and save
    face = frame[y1:y2, x1:x2]
    if face.size == 0:
        pbar.update(1)
        continue

    face_resized = cv2.resize(face, crop_size)
    cv2.imwrite(crop_path, face_resized)
    processed += 1
    pbar.update(1)

pbar.close()
cap.release()
print(f"✅ Cropping done! Total faces saved: {processed}")

!pip install deepface

!pip uninstall -y numpy deepface pandas

!pip install numpy==1.24.4 pandas==2.2.2 deepface==0.0.93

# 🔁 Reset Colab environment
!pip uninstall -y numpy pandas deepface
!pip install numpy==1.24.4 pandas==1.5.3 deepface==0.0.93 --quiet

# ✅ Now import safely
from deepface import DeepFace
import cv2
import numpy as np
import pandas as pd
import os

!pip uninstall -y tensorflow keras tf-keras tensorflow-estimator protobuf
!pip install deepface==0.0.93 pandas==1.5.3 numpy==1.24.4 tensorflow==2.11.0 --quiet

!pip install deepface==0.0.93 tensorflow==2.17.1 pandas==2.2.2 numpy==1.24.4 --force-reinstall --quiet

!pip uninstall -y numpy pandas
!pip install numpy==1.24.3 pandas==1.5.3 tensorflow==2.11.0 keras==2.11.0 deepface==0.0.75 --quiet

!pip install -U --quiet numpy==1.24.4 pandas==2.2.2 tensorflow==2.17.1 keras==2.13.1 deepface==0.0.93

# prompt: install DeepFace

!pip install deepface

from deepface import DeepFace

model = DeepFace.build_model("Facenet512")
print("✅ Model loaded successfully!")

import os
from PIL import Image
from IPython.display import display

# ✅ Filter out only JPG images
images = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

# Preview the first valid image
from PIL import Image
from IPython.display import display
img = Image.open(os.path.join(folder_path, images[0]))
display(img)

from deepface import DeepFace

test_img = os.path.join(folder_path, images[0])
embedding = DeepFace.represent(img_path=test_img, model_name="Facenet512", enforce_detection=True)
print("✅ Embedding created:", embedding)

# ✅ Imports
from deepface import DeepFace
import numpy as np
import pandas as pd
import cv2
import os
from PIL import Image
from tqdm import tqdm

# ✅ Google Drive Mount
from google.colab import drive
drive.mount('/content/drive')

# ✅ Set test image path
test_img_path = "/content/drive/MyDrive/SAFF_Faces/SAFF WOMEN/Mubarkah Mohammed/MubarkahMohammed1.jpg"

# ✅ Load DeepFace model (Facenet512)
model_name = "Facenet512"
model = DeepFace.build_model(model_name)
print("✅ Model loaded!")

# ✅ Generate embedding for the test image
test_embedding = DeepFace.represent(img_path=test_img_path, model_name=model_name, enforce_detection=False)[0]["embedding"]

# ✅ Print embedding shape and a small part of the vector
print(f"✅ Embedding generated! Length: {len(test_embedding)}")
print(test_embedding[:10])  # Show first 10 values

from deepface import DeepFace
import os
import pickle
from tqdm import tqdm

# ✅ Define root directory where each player's folder is located
root_dir = "/content/drive/MyDrive/SAFF_Faces/SAFF WOMEN"

# ✅ Initialize storage for embeddings
embeddings = []

# ✅ Loop through each player folder
for player_name in tqdm(os.listdir(root_dir)):
    player_folder = os.path.join(root_dir, player_name)

    if not os.path.isdir(player_folder):
        continue  # Skip files

    for img_name in os.listdir(player_folder):
        if img_name.lower().endswith((".jpg", ".jpeg", ".png")):
            img_path = os.path.join(player_folder, img_name)
            try:
                embedding = DeepFace.represent(img_path=img_path, model_name="Facenet512", enforce_detection=False)[0]["embedding"]
                embeddings.append({
                    "player": player_name,
                    "image": img_name,
                    "embedding": embedding
                })
            except Exception as e:
                print(f"❌ Error with {player_name}/{img_name}: {e}")

# ✅ Save the embeddings to a file for later use
with open("/content/drive/MyDrive/SAFF_Faces/face_embeddings.pkl", "wb") as f:
    pickle.dump(embeddings, f)

print("✅ All player embeddings saved successfully!")

import numpy as np

# ✅ Load the saved embeddings
with open("/content/drive/MyDrive/SAFF_Faces/face_embeddings.pkl", "rb") as f:
    embeddings = pickle.load(f)

# 📸 Set the path to your test face image
test_img_path = "/content/drive/MyDrive/SAFF_Faces/SAFF WOMEN/Mubarkah Mohammed/MubarkahMohammed1.jpg"

# ✅ Create test face embedding
test_embedding = DeepFace.represent(img_path=test_img_path, model_name="Facenet512", enforce_detection=False)[0]["embedding"]

# ✅ Compare to all stored embeddings using cosine distance
def cosine_distance(vec1, vec2):
    vec1 = np.array(vec1)
    vec2 = np.array(vec2)
    return 1 - np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

# 🔍 Find closest match
best_match = None
best_score = float("inf")

for emb in embeddings:
    score = cosine_distance(test_embedding, emb["embedding"])
    if score < best_score:
        best_score = score
        best_match = emb

# 🎯 Show result
print(f"\n🎯 Best match: {best_match['player']} ({best_match['image']})")
print(f"📏 Cosine similarity distance: {best_score:.4f}")

# 📦 Re-import everything after installation (in a new cell)
from deepface import DeepFace
import os
import numpy as np
from tqdm import tqdm
import cv2

# 📂 Set paths
dataset_path = "/content/drive/MyDrive/SAFF_Faces/SAFF WOMEN"
test_img_path = "/content/drive/MyDrive/SAFF_Faces/SAFF WOMEN/Mubarkah Mohammed/MubarkahMohammed1.jpg"

# ✅ Load all embeddings
embeddings = []
names = []

# 📦 Loop through players
for player_name in tqdm(os.listdir(dataset_path)):
    player_folder = os.path.join(dataset_path, player_name)
    if not os.path.isdir(player_folder):
        continue
    for img_file in os.listdir(player_folder):
        if img_file.endswith(".jpg"):
            img_path = os.path.join(player_folder, img_file)
            try:
                result = DeepFace.represent(img_path=img_path, model_name="Facenet512", enforce_detection=False)
                embeddings.append(result[0]["embedding"])
                names.append((player_name, img_file))
            except Exception as e:
                print(f"❌ Error processing {img_file} for {player_name}: {e}")

# ✅ Represent test image
test_embedding = DeepFace.represent(img_path=test_img_path, model_name="Facenet512", enforce_detection=False)[0]["embedding"]

# 🔍 Cosine similarity
def cosine_similarity(a, b):
    a, b = np.array(a), np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# 🎯 Find best match
best_score = -1
best_match = None

for i, emb in enumerate(embeddings):
    score = cosine_similarity(test_embedding, emb)
    if score > best_score:
        best_score = score
        best_match = names[i]

best_match_name, best_match_img = best_match
print(f"\n🎯 Best match: {best_match_name} ({best_match_img})")
print(f"📏 Cosine similarity distance: {1 - best_score:.4f}")

# 📍 Make sure this runs right after you create embeddings
with open("/content/drive/MyDrive/TG_TACTICS/player_embeddings.pkl", "wb") as f:
    pickle.dump(database, f)

print("✅ Embeddings saved to Google Drive!")

from deepface import DeepFace
import cv2
import os
import pickle
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
from numpy.linalg import norm

# ✅ Test image
test_img_path = "/content/drive/MyDrive/SAFF_Faces/SAFF WOMEN/Mubarkah Mohammed/MubarkahMohammed1.jpg"

# ✅ Load saved player embeddings
with open("/content/drive/MyDrive/TG_TACTICS/player_embeddings.pkl", "rb") as f:
    database = pickle.load(f)

# ✅ Create embedding for the test image
test_embedding = DeepFace.represent(img_path=test_img_path, model_name="Facenet512", enforce_detection=False)[0]["embedding"]

# ✅ Cosine similarity function
def cosine_similarity(vec1, vec2):
    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))

# ✅ Match
best_match = None
best_score = -1

for entry in database:
    name, embedding = entry  # Only 2 values now
    sim = cosine_similarity(test_embedding, embedding)
    if sim > best_score:
        best_score = sim
        best_match = entry

# ✅ Display test and best match images
fig, ax = plt.subplots(1, 2, figsize=(10, 5))

# Test image
img1 = Image.open(test_img_path)
ax[0].imshow(img1)
ax[0].set_title("🎯 Test Image")
ax[0].axis("off")

# Match image (find the 1st image from folder)
match_name = best_match[0]
match_folder = f"/content/drive/MyDrive/SAFF_Faces/SAFF WOMEN/{match_name}"
match_img = sorted([f for f in os.listdir(match_folder) if f.lower().endswith(".jpg")])[0]
match_img_path = os.path.join(match_folder, match_img)

img2 = Image.open(match_img_path)
ax[1].imshow(img2)
ax[1].set_title(f"✅ Match: {match_name}")
ax[1].axis("off")

plt.suptitle(f"📏 Cosine Similarity: {best_score:.4f}", fontsize=12)
plt.tight_layout()
plt.show()

!ls /content/drive/MyDrive/player_embeddings.pkl

# ✅ Google Drive Mount
from google.colab import drive
drive.mount('/content/drive')

import os
import pickle
import numpy as np
from tqdm import tqdm
from deepface import DeepFace
from PIL import Image

# ✅ Cosine similarity function
def cosine_similarity(v1, v2):
    v1 = np.array(v1)
    v2 = np.array(v2)
    return np.dot(v1, v2.T) / (np.linalg.norm(v1) * np.linalg.norm(v2))

# ✅ Load the embeddings
embedding_path = "/content/drive/MyDrive/player_embeddings.pkl"
with open(embedding_path, "rb") as f:
    database = pickle.load(f)

# ✅ Print all available names for confirmation
print("Available player names in embeddings:")
for entry in database:
    print("-", entry[0])

# ✅ Replace this with the confirmed correct player name from the above output
player_name = "MubarkahMohammed"  # Make sure this matches exactly

# ✅ Get Mubarkah's embedding
mubarkah_embedding = None
for entry in database:
    if entry[0] == player_name:
        mubarkah_embedding = entry[2]
        break

if mubarkah_embedding is None:
    print("❌ Couldn't find embedding for", player_name)
else:
    print("✅ Found embedding for", player_name)

    # ✅ Path to match frames (edit if needed)
    match_folder = "/content/drive/MyDrive/TG_TACTICS/Cropped_Faces/Match_3/track_993"

    best_score = -1
    best_match_path = None

    # ✅ Scan through all frames and compare
    for file in tqdm(sorted(os.listdir(match_folder))):
        if not file.lower().endswith((".jpg", ".png")):
            continue

        img_path = os.path.join(match_folder, file)

        try:
            result = DeepFace.represent(img_path=img_path, model_name="Facenet512", enforce_detection=False)
            if result and "embedding" in result[0]:
                embedding = result[0]["embedding"]
                score = cosine_similarity(mubarkah_embedding, embedding)
                if score > best_score:
                    best_score = score
                    best_match_path = img_path
        except Exception as e:
            print(f"⚠️ Error on {file}: {e}")

    # ✅ Result
    if best_match_path:
        print("\n🎯 Best matching frame:", best_match_path)
        print("📏 Cosine similarity:", best_score)
    else:
        print("❌ No matching frame found.")

from deepface import DeepFace
import cv2
import os
import numpy as np
from tqdm import tqdm
import pickle
import matplotlib.pyplot as plt

# ✅ Set paths
match_folder = "/content/drive/MyDrive/TG_TACTICS/Cropped_Faces/Match_3/track_993"
embeddings_path = "/content/drive/MyDrive/player_embeddings.pkl"
player_name = "Albandari Mubarak"
model_name = "Facenet512"

# ✅ Load model
model = DeepFace.build_model(model_name)

# ✅ Load embeddings database
with open(embeddings_path, "rb") as f:
    database = pickle.load(f)

# ✅ Extract player's embeddings (handles 2 or 3 element tuples)
player_embeddings = []
for entry in database:
    if isinstance(entry, tuple) and len(entry) >= 2:
        name = entry[0]
        embedding = entry[-1]
        if name == player_name:
            player_embeddings.append(embedding)

if not player_embeddings:
    print(f"❌ Couldn't find embedding for {player_name}")
else:
    print(f"✅ Found {len(player_embeddings)} embeddings for {player_name}")

    # ✅ Cosine similarity function
    def cosine_similarity(v1, v2):
        return np.dot(v1, v2.T) / (np.linalg.norm(v1) * np.linalg.norm(v2))

    # ✅ Search through frames
    best_frame = None
    best_score = -1

    for file in tqdm(sorted(os.listdir(match_folder))):
        if not file.lower().endswith((".jpg", ".png")):
            continue

        try:
            img_path = os.path.join(match_folder, file)
            result = DeepFace.represent(img_path=img_path, model_name=model_name, model=model, enforce_detection=False)

            if result and isinstance(result, list):
                test_embedding = result[0]["embedding"]
                for emb in player_embeddings:
                    score = cosine_similarity(test_embedding, emb)
                    if score > best_score:
                        best_score = score
                        best_frame = file

        except Exception as e:
            print(f"⚠️ Error on {file}: {e}")

    # ✅ Show result
    if best_frame:
        print(f"\n🎯 Best match: {best_frame}")
        print(f"📏 Cosine similarity: {best_score:.4f}")

        frame_path = os.path.join(match_folder, best_frame)
        img = cv2.imread(frame_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        plt.imshow(img)
        plt.title(f"Best match for {player_name}")
        plt.axis("off")
        plt.show()
    else:
        print("❌ No matching frame found.")

from deepface import DeepFace
import cv2
import os
import numpy as np
from tqdm import tqdm
import pickle
import matplotlib.pyplot as plt

# ✅ Set paths
match_folder = "/content/drive/MyDrive/TG_TACTICS/Cropped_Faces/Match_3/track_993"
embeddings_path = "/content/drive/MyDrive/player_embeddings.pkl"
player_name = "Albandari Mubarak"
model_name = "Facenet512"

# ✅ Load embeddings database
with open(embeddings_path, "rb") as f:
    database = pickle.load(f)

# ✅ Extract player's embeddings (handles 2 or 3 element tuples)
player_embeddings = []
for entry in database:
    if isinstance(entry, tuple) and len(entry) >= 2:
        name = entry[0]
        embedding = entry[-1]
        if name == player_name:
            player_embeddings.append(embedding)

if not player_embeddings:
    print(f"❌ Couldn't find embedding for {player_name}")
else:
    print(f"✅ Found {len(player_embeddings)} embeddings for {player_name}")

    # ✅ Cosine similarity function
    def cosine_similarity(v1, v2):
        return np.dot(v1, v2.T) / (np.linalg.norm(v1) * np.linalg.norm(v2))

    # ✅ Search through frames
    best_frame = None
    best_score = -1

    for file in tqdm(sorted(os.listdir(match_folder))):
        if not file.lower().endswith((".jpg", ".png")):
            continue

        try:
            img_path = os.path.join(match_folder, file)
            result = DeepFace.represent(img_path=img_path, model_name=model_name, enforce_detection=False)

            if result and isinstance(result, list):
                test_embedding = result[0]["embedding"]
                for emb in player_embeddings:
                    score = cosine_similarity(test_embedding, emb)
                    if score > best_score:
                        best_score = score
                        best_frame = file

        except Exception as e:
            print(f"⚠️ Error on {file}: {e}")

    # ✅ Show result
    if best_frame:
        print(f"\n🎯 Best match: {best_frame}")
        print(f"📏 Cosine similarity: {best_score:.4f}")

        frame_path = os.path.join(match_folder, best_frame)
        img = cv2.imread(frame_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        plt.imshow(img)
        plt.title(f"Best match for {player_name}")
        plt.axis("off")
        plt.show()
    else:
        print("❌ No matching frame found.")

import os
import cv2
import numpy as np
import pickle
from deepface import DeepFace
from tqdm import tqdm
from matplotlib import pyplot as plt

# ✅ Define target player name
player_name = "Sara Alhamad"

# ✅ Path to player embeddings
embeddings_path = "/content/drive/MyDrive/player_embeddings.pkl"

# ✅ Load embeddings
with open(embeddings_path, "rb") as f:
    database = pickle.load(f)

# ✅ Extract player embeddings (Assuming each entry = (name, embedding))
player_embeddings = [np.array(entry[1]) for entry in database if entry[0] == player_name]

if not player_embeddings:
    print(f"❌ Couldn't find embeddings for {player_name}")
else:
    print(f"✅ Found {len(player_embeddings)} embeddings for {player_name}")

    # ✅ Path to cropped face frames of Match_3 (change if needed)
    match_folder = "/content/drive/MyDrive/TG_TACTICS/Cropped_Faces/Match_3/track_993"

    best_score = -1
    best_frame = None

    def cosine_similarity(v1, v2):
        return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

    # ✅ Loop over each frame
    for file in tqdm(sorted(os.listdir(match_folder))):
        if not file.lower().endswith((".jpg", ".png")):
            continue

        try:
            frame_path = os.path.join(match_folder, file)

            # Get embedding of face in the frame
            test_embedding = DeepFace.represent(
                img_path=frame_path,
                model_name="Facenet512",
                enforce_detection=False
            )[0]["embedding"]
            test_embedding = np.array(test_embedding)

            # Compare with player embeddings
            for player_embed in player_embeddings:
                sim = cosine_similarity(test_embedding, player_embed)
                if sim > best_score:
                    best_score = sim
                    best_frame = file

        except Exception as e:
            print(f"⚠️ Error on {file}: {e}")

    if best_frame:
        print(f"\n🎯 Best match for {player_name}: {best_frame}")
        print(f"📏 Cosine similarity: {best_score:.4f}")

        # ✅ Visualize
        full_path = os.path.join(match_folder, best_frame)
        img = cv2.imread(full_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        plt.imshow(img_rgb)
        plt.title(f"{player_name} - {best_frame}")
        plt.axis("off")
        plt.show()
    else:
        print("❌ No matching frame found.")

# ✅ Google Drive Mount
from google.colab import drive
drive.mount('/content/drive')

!pip install deepface

from deepface import DeepFace
import os
import cv2
import numpy as np
import pickle
from tqdm import tqdm
from matplotlib import pyplot as plt

# ✅ Set paths
clustered_path = "/content/drive/MyDrive/player_data/clustered_players"
embeddings_path = "/content/drive/MyDrive/player_embeddings.pkl"
target_name = "Albandari Mubarak"

# ✅ Load player embeddings
with open(embeddings_path, "rb") as f:
    database = pickle.load(f)

# ✅ Get embeddings for the target player
player_embeddings = [np.array(entry[1]) for entry in database if entry[0] == target_name]

if not player_embeddings:
    print(f"❌ No embeddings found for {target_name}")
else:
    print(f"✅ Found {len(player_embeddings)} embeddings for {target_name}")

# ✅ Cosine similarity function
def cosine_similarity(v1, v2):
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

# ✅ Search all clustered players folders
best_score = -1
best_frame_path = None

for person_folder in tqdm(sorted(os.listdir(clustered_path))):
    folder_path = os.path.join(clustered_path, person_folder)
    if not os.path.isdir(folder_path): continue

    for img_file in os.listdir(folder_path):
        if not img_file.lower().endswith((".jpg", ".png")): continue
        img_path = os.path.join(folder_path, img_file)

        try:
            result = DeepFace.represent(img_path=img_path, model_name="Facenet512", enforce_detection=False)
            if result:
                test_embedding = np.array(result[0]["embedding"])
                for embed in player_embeddings:
                    sim = cosine_similarity(test_embedding, embed)
                    if sim > best_score:
                        best_score = sim
                        best_frame_path = img_path
        except Exception as e:
            print(f"⚠️ Error on {img_file}: {e}")

# ✅ Display best match
if best_frame_path:
    print(f"\n🎯 Best match: {best_frame_path}")
    print(f"📏 Cosine similarity: {best_score:.4f}")

    # Show the image
    img = cv2.imread(best_frame_path)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title(f"Best match for {target_name}")
    plt.axis("off")
    plt.show()
else:
    print("❌ No matching frame found.")

print("First 3 embeddings in database:")
for entry in database[:3]:
    print(entry)

from deepface import DeepFace
import os, pickle
from tqdm import tqdm

clustered_folder = "/content/drive/MyDrive/player_data/clustered_players"
embeddings = []

for player in sorted(os.listdir(clustered_folder)):
    player_folder = os.path.join(clustered_folder, player)
    if not os.path.isdir(player_folder):
        continue

    for img_file in os.listdir(player_folder):
        img_path = os.path.join(player_folder, img_file)
        try:
            result = DeepFace.represent(img_path=img_path, model_name="Facenet512", enforce_detection=False)
            embedding = result[0]["embedding"]
            embeddings.append((player, img_file, embedding))
        except Exception as e:
            print(f"⚠️ Error with {img_path}: {e}")

# ✅ Save
with open("/content/drive/MyDrive/player_embeddings.pkl", "wb") as f:
    pickle.dump(embeddings, f)

print("✅ New embeddings saved!")

import pickle

# Load the saved player embeddings
with open("/content/drive/MyDrive/player_embeddings.pkl", "rb") as f:
    database = pickle.load(f)

# Create a mapping of person folders to real names
name_map = {}
for i, entry in enumerate(database):
    if len(entry) == 3:
        name, img_name, embedding = entry
        folder = f"Person_{i}"
        name_map[folder] = name

# Print to verify
print(name_map)

# 👇 Force reinstall of correct versions
!pip uninstall -y numpy
!pip install numpy==1.23.5  # norfair works well with this version
!pip install filterpy==1.4.5
!pip install norfair==1.0.0.post2
!pip install ultralytics==8.0.20
!pip install opencv-python-headless==4.8.0.74

!pip install -q ultralytics
!pip install -q opencv-python-headless
!pip install -q norfair

from ultralytics import YOLO
import cv2
import os
import pandas as pd
from norfair import Detection, Tracker
from tqdm import tqdm

!wget https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt -O yolov5_model.pt

!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt -O /content/drive/MyDrive/TG_TACTICS/yolov8_model.pt

# Define your model path and tracking output folder
model_path = "/content/drive/MyDrive/TG_TACTICS/yolov8_model.pt"  # change if needed
video_folder = "/content/drive/MyDrive/Matches_Folder"
output_folder = "/content/drive/MyDrive/TG_TACTICS"

# Load the YOLO model
model = YOLO(model_path)
print("✅ YOLO model loaded")

def frame_to_detections(yolo_results, conf_thres=0.25):
    dets = []
    for box in yolo_results.boxes:
        if box.conf[0] < conf_thres:
            continue
        x1, y1, x2, y2 = box.xyxy[0].tolist()
        dets.append(Detection(points=[[(x1 + x2) / 2, (y1 + y2) / 2]], scores=[box.conf[0]]))
    return dets



"""-----------------------**START FROM HERE**-----------------------"""